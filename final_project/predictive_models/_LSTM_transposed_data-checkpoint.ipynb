{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade7386e",
   "metadata": {},
   "source": [
    "# Predicting Energy Consumption\n",
    "\n",
    "In the dataset, there are energy levels recorded for 15 different power plants for each hour in the day; i.e., there are 24 variables, in addition to ID columns, such as date and plant ID.\n",
    "\n",
    "In the temperature dataset, there are temperatures recorded for 9 different stations for each hour in the day, i.e., there are 24 variables. \n",
    "\n",
    "This predicition model will simply attempt to predict loads based on loads from the other 23 hours, without considering temperatures as variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe31313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0cd4238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_5204\\189144393.py:1: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\Matthew\\PycharmProjects\\ISDS-7075-Project\\final_project\\datasets\\transposed.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Matthew\\PycharmProjects\\ISDS-7075-Project\\final_project\\datasets\\transposed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc0d77cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>S7</th>\n",
       "      <th>S8</th>\n",
       "      <th>S9</th>\n",
       "      <th>load</th>\n",
       "      <th>zone_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1/1/2015 1:00</th>\n",
       "      <td>45.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>66025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2015 2:00</th>\n",
       "      <td>41.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2015 3:00</th>\n",
       "      <td>40.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>63898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2015 4:00</th>\n",
       "      <td>39.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>64078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2015 5:00</th>\n",
       "      <td>43.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>65734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 S1    S2    S3    S4    S5    S6    S7    S8    S9   load  \\\n",
       "date                                                                         \n",
       "1/1/2015 1:00  45.0  55.0  47.0  53.0  54.0  51.0  53.0  54.0  52.0  66025   \n",
       "1/1/2015 2:00  41.0  55.0  45.0  51.0  52.0  51.0  52.0  53.0  53.0  64655   \n",
       "1/1/2015 3:00  40.0  54.0  44.0  49.0  50.0  49.0  51.0  50.0  51.0  63898   \n",
       "1/1/2015 4:00  39.0  50.0  39.0  45.0  46.0  48.0  47.0  49.0  43.0  64078   \n",
       "1/1/2015 5:00  43.0  48.0  39.0  43.0  42.0  49.0  47.0  44.0  39.0  65734   \n",
       "\n",
       "               zone_id  \n",
       "date                    \n",
       "1/1/2015 1:00        1  \n",
       "1/1/2015 2:00        1  \n",
       "1/1/2015 3:00        1  \n",
       "1/1/2015 4:00        1  \n",
       "1/1/2015 5:00        1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index('date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63dc77ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fixing data types to float\n",
    "\n",
    "temp_cols = ['S1','S2','S3','S4','S5','S6','S7','S8','S9']\n",
    "\n",
    "def floater(index):\n",
    "    for i in index:\n",
    "        df[index] = pd.to_numeric(df[index], errors='coerce')\n",
    "        return df[index]\n",
    "    \n",
    "S1 = floater('S1')\n",
    "S2 = floater('S2')\n",
    "S3 = floater('S3')\n",
    "S4 = floater('S4')\n",
    "S5 = floater('S5')\n",
    "S6 = floater('S6')\n",
    "S7 = floater('S7')\n",
    "S8 = floater('S8')\n",
    "S9 = floater('S9')\n",
    "\n",
    "df['S1'] = S1\n",
    "df['S2'] = S2\n",
    "df['S3'] = S3\n",
    "df['S4'] = S4\n",
    "df['S5'] = S5\n",
    "df['S6'] = S6\n",
    "df['S7'] = S7\n",
    "df['S8'] = S8\n",
    "df['S9'] = S9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "29bc31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfLoadHistory = dfRAWLoadHistory[(dfRAWLoadHistory.obsn != \"total\")&(~dfRAWLoadHistory['h1'].isnull())]\n",
    "\n",
    "def trainer(index_to_stop):\n",
    "    df_for_training = df[~df['load'].isnull()]\n",
    "    df_for_training = df.iloc[0:index_to_stop,0:10].astype(float)\n",
    "    \n",
    "    return df_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b08fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 154800 entries, 1/1/2015 1:00 to 3/5/2016 0:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   S1      154440 non-null  float64\n",
      " 1   S2      154440 non-null  float64\n",
      " 2   S3      154440 non-null  float64\n",
      " 3   S4      154440 non-null  float64\n",
      " 4   S5      154440 non-null  float64\n",
      " 5   S6      154440 non-null  float64\n",
      " 6   S7      154440 non-null  float64\n",
      " 7   S8      154440 non-null  float64\n",
      " 8   S9      154440 non-null  float64\n",
      " 9   load    154800 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# calling trainer function for first training set\n",
    "\n",
    "df_for_training = trainer(154800)\n",
    "df_for_training.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c0c095b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTSM uses sigmoid and tanh that are sensitive to magnitude, so values need to be normalized\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "57ab7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "\n",
    "n_future = 7\n",
    "n_past = 21\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future + 1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e0c980e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 21, 64)            19200     \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,649\n",
      "Trainable params: 31,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define Autoencoder model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e3c46d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1935/1935 [==============================] - 27s 13ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(x=trainX, y=trainY, epochs=1, batch_size=64, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0b5fb351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Forecasting\n",
    "# start with the last day in training set and predict future\n",
    "n_future = 105\n",
    "# forecast_period_dates = pd.date_range(list(train_dates)[-1], periods=n_future, freq='1d').tolist()\n",
    "\n",
    "forecast = model.predict(trainX[-n_future:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a412b5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "# Perform inverse transformation to rescale back to original range\n",
    "\n",
    "forecast_copies = np.repeat(forecast, df_for_training.shape[1], axis=-1)\n",
    "h1_future = scaler.inverse_transform(forecast_copies)[:,0]\n",
    "\n",
    "\n",
    "print(h1_future)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ced986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4455a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isdsenv",
   "language": "python",
   "name": "isdsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
